{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbacc371",
   "metadata": {},
   "source": [
    "# Traffic Detection on road "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "38f34ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import shutil\n",
    "import random\n",
    "import glob\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "%matplotlib inline\n",
    "import pandas as pd              \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt  \n",
    "import PIL       \n",
    "import PIL.Image\n",
    "import os       \n",
    "import os.path\n",
    "from PIL import Image\n",
    "import cv2 as cv\n",
    "import cv2\n",
    "from scipy.stats import stats\n",
    "import pickle\n",
    "from sklearn. model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer   # to normalize sift feature extracted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c7e47d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open('RFC.sav', 'rb')\n",
    "model = pickle.load(pickle_in )\n",
    "pickle_in.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9e86fb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(r'C:\\Users\\Administrator\\Desktop\\college\\TY\\Sem2\\CV\\CP\\Kmeans_CL_5_Model.sav', 'rb')\n",
    "kmeans = pickle.load(pickle_in )\n",
    "pickle_in.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "346084d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load previously dumped hog image dataset \n",
    "pickle_in = open(r'C:\\Users\\Administrator\\Desktop\\college\\TY\\Sem2\\CV\\CP\\PCA_3_Model.sav', 'rb')\n",
    "pca = pickle.load(pickle_in )\n",
    "pickle_in.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "640d52fb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3001, 13)\n",
      "[0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0\n",
      " 1 1 1 0 1 1 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 0 0 1 0 0 1 0 0 1 0 0 1 1\n",
      " 1 1 1 0 1 0 1 0 0 1 0 1 1 0 1 1 0 1 0 0 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 0 1 1 1 1 0 1 1 1 1 0 0 0 1 1 1 1 0 0 1 1 0 0 1 0 1 0 0 1 1 1 1 1 1 0\n",
      " 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 1 1 1 1\n",
      " 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 0 0 0 0 0 1 1 1 1\n",
      " 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 1 1 1 0 1\n",
      " 1 1 1 1 1 0 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 0 0 1 1 0 1 0 1 0 0 1 0 1 1 1 0\n",
      " 1 1 1 0 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0\n",
      " 0 1 1 0 0 1 1 1 0 1 1 0 0 0 1 1 1 1 1 0 1 0 1 1 1 1 0 1 1 1 0 1 0 0 1 1 1\n",
      " 1 0 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 1 1 1 0 1 1 0 0 1 0 1 0 0 1 1 1 1\n",
      " 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 0 1 1 0 1 1 0 0 1 0 1 1 1 0 1 1 1 1 0 1 0\n",
      " 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 0 0 0 0 1 1 1 0 1 0 1 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 1 1 1 1 0 1 0 1 0 0 0 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 1\n",
      " 0 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1\n",
      " 0 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 1 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 0 0 1 0 1 1 1 0 1 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 0 0 1 1\n",
      " 0 0 1 1 0 1 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 1 0 1 1 1 0 1 1\n",
      " 1 0 0 1 0 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1\n",
      " 0 1 0 1 1 1 0 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 0 1 1 0 1 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 0 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 1 1 0 0 0 0 1 0 1 0 1 0 1 1 0\n",
      " 1 1 1 0 0 1 1 0 1 1 1 1 0 0 0 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
      " 1 1 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 1 0 0 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1\n",
      " 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 1 1 1\n",
      " 1]\n",
      "Traffic : 694\n",
      "Non Traffic : 306\n"
     ]
    }
   ],
   "source": [
    "b=r'C:\\Users\\Administrator\\Desktop\\college\\TY\\Sem2\\CV\\CP\\database\\P-img'\n",
    "data =[]\n",
    "for filename in os.listdir(b):\n",
    "    \n",
    "    path=os.path.join(b,filename)\n",
    "    a=cv2.imread(path)\n",
    "    \n",
    "    #resize imageAC\n",
    "    resize=(430,280)\n",
    "    img=cv2.resize(a,resize)\n",
    "    \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    #initialise sift descriptor\n",
    "    orb = cv2.ORB_create()\n",
    "    keypoints, descriptors = orb.detectAndCompute(gray, None)\n",
    "\n",
    "    #convert the descriptor array into a dataframe format\n",
    "    out=pd.DataFrame(descriptors)\n",
    "    array_double = np.array(out, dtype=np.double)\n",
    "#     print(out)\n",
    "\n",
    "    a=kmeans.predict(array_double) \n",
    "    hist=np.histogram(a,bins=[0,1,2,3,4,5,6,7,8,9,10,11,12,13])\n",
    "    data.append(hist[0])\n",
    "    Output = pd.DataFrame(data)\n",
    "    #print(\"Histogram:\\n\",Output)\n",
    "\n",
    "norm = Normalizer()\n",
    "normalized = norm.fit_transform(Output)  \n",
    "normalized.shape# normalize \n",
    "\n",
    "Standardize = StandardScaler()\n",
    "x_scaled = Standardize.fit_transform(normalized)\n",
    "pd.DataFrame(normalized)\n",
    "print(x_scaled.shape)\n",
    "\n",
    "\n",
    "x_pca = pca.transform(x_scaled)\n",
    "x_pca = pd.DataFrame(x_pca)\n",
    "x_pca\n",
    "\n",
    "# First 1000 images are of traffic\n",
    "m = x_pca.iloc[:1000,:]\n",
    "#prediction\n",
    "y_pred1 = model.predict(m)\n",
    "\n",
    "#prints the prediction of the class\n",
    "print(y_pred1)\n",
    "a=np.count_nonzero(y_pred1==1)\n",
    "print(\"Traffic :\",a)\n",
    "a=np.count_nonzero(y_pred1==0)\n",
    "print(\"Non Traffic :\",a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270f50b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
